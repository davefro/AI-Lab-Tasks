{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"id":"jbD2qQ7olRCK"},"outputs":[],"source":["#Downloading the Titanic dataset from Kaggle and save it to orig_df, a copy is provided with this exercise and you can upload it to your drive folder.\n","import pandas as pd\n","df = pd.read_csv('/Users/dawidfroncisz/Desktop/AI-Lab-Tasks/Session 5/titanic3.csv')\n","orig_df = df"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"1K0uyx8vlRCO"},"outputs":[{"name":"stdout","output_type":"stream","text":["      pclass  survived                                             name  \\\n","0          1         1                    Allen, Miss. Elisabeth Walton   \n","1          1         1                   Allison, Master. Hudson Trevor   \n","2          1         0                     Allison, Miss. Helen Loraine   \n","3          1         0             Allison, Mr. Hudson Joshua Creighton   \n","4          1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)   \n","...      ...       ...                                              ...   \n","1304       3         0                             Zabour, Miss. Hileni   \n","1305       3         0                            Zabour, Miss. Thamine   \n","1306       3         0                        Zakarian, Mr. Mapriededer   \n","1307       3         0                              Zakarian, Mr. Ortin   \n","1308       3         0                               Zimmerman, Mr. Leo   \n","\n","         sex    age  sibsp  parch  ticket      fare    cabin embarked boat  \\\n","0     female  29.00      0      0   24160  211.3375       B5        S    2   \n","1       male   0.92      1      2  113781  151.5500  C22 C26        S   11   \n","2     female   2.00      1      2  113781  151.5500  C22 C26        S  NaN   \n","3       male  30.00      1      2  113781  151.5500  C22 C26        S  NaN   \n","4     female  25.00      1      2  113781  151.5500  C22 C26        S  NaN   \n","...      ...    ...    ...    ...     ...       ...      ...      ...  ...   \n","1304  female  14.50      1      0    2665   14.4542      NaN        C  NaN   \n","1305  female    NaN      1      0    2665   14.4542      NaN        C  NaN   \n","1306    male  26.50      0      0    2656    7.2250      NaN        C  NaN   \n","1307    male  27.00      0      0    2670    7.2250      NaN        C  NaN   \n","1308    male  29.00      0      0  315082    7.8750      NaN        S  NaN   \n","\n","       body                        home.dest  \n","0       NaN                     St Louis, MO  \n","1       NaN  Montreal, PQ / Chesterville, ON  \n","2       NaN  Montreal, PQ / Chesterville, ON  \n","3     135.0  Montreal, PQ / Chesterville, ON  \n","4       NaN  Montreal, PQ / Chesterville, ON  \n","...     ...                              ...  \n","1304  328.0                              NaN  \n","1305    NaN                              NaN  \n","1306  304.0                              NaN  \n","1307    NaN                              NaN  \n","1308    NaN                              NaN  \n","\n","[1309 rows x 14 columns]\n"]}],"source":["#Explore the Titanic dataset\n","#Print all samples and check how many samples and features the Titanic dataset has\n","print(orig_df)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"ZR5C2VS9lRCQ"},"outputs":[{"data":{"text/plain":["pclass         int64\n","survived       int64\n","name          object\n","sex           object\n","age          float64\n","sibsp          int64\n","parch          int64\n","ticket        object\n","fare         float64\n","cabin         object\n","embarked      object\n","boat          object\n","body         float64\n","home.dest     object\n","dtype: object"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["#Check the type of each variable (data type)\n","#int type is ok, float64 is ok as well but you may change it to int, object type need to be changed to int (object is a string in pandas and perform a string operation)\n","df.dtypes"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      pclass  survived                                             name  sex  \\\n","0          1         1                    Allen, Miss. Elisabeth Walton    0   \n","1          1         1                   Allison, Master. Hudson Trevor    1   \n","2          1         0                     Allison, Miss. Helen Loraine    0   \n","3          1         0             Allison, Mr. Hudson Joshua Creighton    1   \n","4          1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)    0   \n","...      ...       ...                                              ...  ...   \n","1304       3         0                             Zabour, Miss. Hileni    0   \n","1305       3         0                            Zabour, Miss. Thamine    0   \n","1306       3         0                        Zakarian, Mr. Mapriededer    1   \n","1307       3         0                              Zakarian, Mr. Ortin    1   \n","1308       3         0                               Zimmerman, Mr. Leo    1   \n","\n","        age  sibsp  parch  ticket      fare    cabin  embarked  boat   body  \\\n","0     29.00      0      0   24160  211.3375       B5         2    11    NaN   \n","1      0.92      1      2  113781  151.5500  C22 C26         2     2    NaN   \n","2      2.00      1      2  113781  151.5500  C22 C26         2    27    NaN   \n","3     30.00      1      2  113781  151.5500  C22 C26         2    27  135.0   \n","4     25.00      1      2  113781  151.5500  C22 C26         2    27    NaN   \n","...     ...    ...    ...     ...       ...      ...       ...   ...    ...   \n","1304  14.50      1      0    2665   14.4542      NaN         0    27  328.0   \n","1305    NaN      1      0    2665   14.4542      NaN         0    27    NaN   \n","1306  26.50      0      0    2656    7.2250      NaN         0    27  304.0   \n","1307  27.00      0      0    2670    7.2250      NaN         0    27    NaN   \n","1308  29.00      0      0  315082    7.8750      NaN         2    27    NaN   \n","\n","      home.dest  \n","0           308  \n","1           230  \n","2           230  \n","3           230  \n","4           230  \n","...         ...  \n","1304        369  \n","1305        369  \n","1306        369  \n","1307        369  \n","1308        369  \n","\n","[1309 rows x 14 columns]\n"]}],"source":["d = {'female': 0, 'male': 1}\n","df['sex'] = df['sex'].map(d)\n","\n","from sklearn import preprocessing\n","\n","le = preprocessing.LabelEncoder()\n","df['embarked'] = le.fit_transform(df['embarked'])\n","df['boat'] = le.fit_transform(df['boat'])\n","df['home.dest'] = le.fit_transform(df['home.dest'])\n","print(df)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>body</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Allen, Miss. Elisabeth Walton</td>\n","      <td>0</td>\n","      <td>29.00</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>24160</td>\n","      <td>211.3375</td>\n","      <td>B5</td>\n","      <td>2</td>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>308</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Allison, Master. Hudson Trevor</td>\n","      <td>1</td>\n","      <td>0.92</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>230</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Allison, Miss. Helen Loraine</td>\n","      <td>0</td>\n","      <td>2.00</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>2</td>\n","      <td>27</td>\n","      <td>NaN</td>\n","      <td>230</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Allison, Mr. Hudson Joshua Creighton</td>\n","      <td>1</td>\n","      <td>30.00</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>2</td>\n","      <td>27</td>\n","      <td>135.0</td>\n","      <td>230</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n","      <td>0</td>\n","      <td>25.00</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>113781</td>\n","      <td>151.5500</td>\n","      <td>C22 C26</td>\n","      <td>2</td>\n","      <td>27</td>\n","      <td>NaN</td>\n","      <td>230</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pclass  survived                                             name  sex  \\\n","0       1         1                    Allen, Miss. Elisabeth Walton    0   \n","1       1         1                   Allison, Master. Hudson Trevor    1   \n","2       1         0                     Allison, Miss. Helen Loraine    0   \n","3       1         0             Allison, Mr. Hudson Joshua Creighton    1   \n","4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)    0   \n","\n","     age  sibsp  parch  ticket      fare    cabin  embarked  boat   body  \\\n","0  29.00      0      0   24160  211.3375       B5         2    11    NaN   \n","1   0.92      1      2  113781  151.5500  C22 C26         2     2    NaN   \n","2   2.00      1      2  113781  151.5500  C22 C26         2    27    NaN   \n","3  30.00      1      2  113781  151.5500  C22 C26         2    27  135.0   \n","4  25.00      1      2  113781  151.5500  C22 C26         2    27    NaN   \n","\n","   home.dest  \n","0        308  \n","1        230  \n","2        230  \n","3        230  \n","4        230  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["pclass          0\n","survived        0\n","name            0\n","sex             0\n","age           263\n","sibsp           0\n","parch           0\n","ticket          0\n","fare            1\n","cabin        1014\n","embarked        0\n","boat            0\n","body         1188\n","home.dest       0\n","dtype: int64"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# fill missing value 'age' and 'fare'\n","df['age'] = df['age'].fillna(df['age'].median())\n","df['fare'] = df['fare'].fillna(df['fare'].median())\n","\n","# drop 'cabin' and 'body' columns\n","df.drop(columns=['cabin', 'body'], inplace=True)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"I68ztCh-lRCQ"},"outputs":[{"data":{"text/plain":["(1309, 12)"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["#Use shape attribute to check the raws (samples) and columns (features)\n","df.shape"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"AfbSc9YPlRCR"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.294882</td>\n","      <td>0.381971</td>\n","      <td>0.644003</td>\n","      <td>29.503186</td>\n","      <td>0.498854</td>\n","      <td>0.385027</td>\n","      <td>33.281086</td>\n","      <td>1.495034</td>\n","      <td>21.576776</td>\n","      <td>270.578304</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.837836</td>\n","      <td>0.486055</td>\n","      <td>0.478997</td>\n","      <td>12.905241</td>\n","      <td>1.041658</td>\n","      <td>0.865560</td>\n","      <td>51.741500</td>\n","      <td>0.816130</td>\n","      <td>8.485711</td>\n","      <td>115.430272</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.170000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.895800</td>\n","      <td>1.000000</td>\n","      <td>17.000000</td>\n","      <td>195.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>323.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.275000</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>512.329200</td>\n","      <td>3.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            pclass     survived          sex          age        sibsp  \\\n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000   \n","mean      2.294882     0.381971     0.644003    29.503186     0.498854   \n","std       0.837836     0.486055     0.478997    12.905241     1.041658   \n","min       1.000000     0.000000     0.000000     0.170000     0.000000   \n","25%       2.000000     0.000000     0.000000    22.000000     0.000000   \n","50%       3.000000     0.000000     1.000000    28.000000     0.000000   \n","75%       3.000000     1.000000     1.000000    35.000000     1.000000   \n","max       3.000000     1.000000     1.000000    80.000000     8.000000   \n","\n","             parch         fare     embarked         boat    home.dest  \n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000  \n","mean      0.385027    33.281086     1.495034    21.576776   270.578304  \n","std       0.865560    51.741500     0.816130     8.485711   115.430272  \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  \n","25%       0.000000     7.895800     1.000000    17.000000   195.000000  \n","50%       0.000000    14.454200     2.000000    27.000000   323.000000  \n","75%       0.000000    31.275000     2.000000    27.000000   369.000000  \n","max       9.000000   512.329200     3.000000    27.000000   369.000000  "]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["#Use describe attribute to explore the data statistics\n","#Can you let me a little bit about the data, for example the age groups\n","# Most passengers were between 22 and 25 years old, the medium is 28 years, min only 0.17 years and max. 80 years\n","df.describe()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"9NKr6g9rlRCS"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.294882</td>\n","      <td>0.381971</td>\n","      <td>0.644003</td>\n","      <td>29.503186</td>\n","      <td>0.498854</td>\n","      <td>0.385027</td>\n","      <td>33.281086</td>\n","      <td>1.495034</td>\n","      <td>21.576776</td>\n","      <td>270.578304</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.837836</td>\n","      <td>0.486055</td>\n","      <td>0.478997</td>\n","      <td>12.905241</td>\n","      <td>1.041658</td>\n","      <td>0.865560</td>\n","      <td>51.741500</td>\n","      <td>0.816130</td>\n","      <td>8.485711</td>\n","      <td>115.430272</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.170000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.895800</td>\n","      <td>1.000000</td>\n","      <td>17.000000</td>\n","      <td>195.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>323.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.275000</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>512.329200</td>\n","      <td>3.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            pclass     survived          sex          age        sibsp  \\\n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000   \n","mean      2.294882     0.381971     0.644003    29.503186     0.498854   \n","std       0.837836     0.486055     0.478997    12.905241     1.041658   \n","min       1.000000     0.000000     0.000000     0.170000     0.000000   \n","25%       2.000000     0.000000     0.000000    22.000000     0.000000   \n","50%       3.000000     0.000000     1.000000    28.000000     0.000000   \n","75%       3.000000     1.000000     1.000000    35.000000     1.000000   \n","max       3.000000     1.000000     1.000000    80.000000     8.000000   \n","\n","             parch         fare     embarked         boat    home.dest  \n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000  \n","mean      0.385027    33.281086     1.495034    21.576776   270.578304  \n","std       0.865560    51.741500     0.816130     8.485711   115.430272  \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  \n","25%       0.000000     7.895800     1.000000    17.000000   195.000000  \n","50%       0.000000    14.454200     2.000000    27.000000   323.000000  \n","75%       0.000000    31.275000     2.000000    27.000000   369.000000  \n","max       9.000000   512.329200     3.000000    27.000000   369.000000  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["#Use describe attribute at different location to explore the data statistics\n","#Use 3 or 4 instead of 2 to include more features (this is useful when you have lots of features)\n","df.describe().iloc[:,:10]"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"mzprieaQlRCS"},"outputs":[{"data":{"text/plain":["pclass       0\n","survived     0\n","name         0\n","sex          0\n","age          0\n","sibsp        0\n","parch        0\n","ticket       0\n","fare         0\n","embarked     0\n","boat         0\n","home.dest    0\n","dtype: int64"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["#Use isnull() to find columns or rows with missing values and sum them up to get the total of missing values\n","#Which features are the leak features?\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"VHa9nQlBlRCT"},"outputs":[],"source":["#We can create a boolean array (a series with True or False to indicate if a row (a sample) has missing data)\n","#and use it to inspect rows that are missing data\n","mask = df.isnull()"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"fGNurzBulRCT"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>name</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>ticket</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pclass  survived   name    sex    age  sibsp  parch  ticket   fare  \\\n","0   False     False  False  False  False  False  False   False  False   \n","1   False     False  False  False  False  False  False   False  False   \n","2   False     False  False  False  False  False  False   False  False   \n","3   False     False  False  False  False  False  False   False  False   \n","4   False     False  False  False  False  False  False   False  False   \n","\n","   embarked   boat  home.dest  \n","0     False  False      False  \n","1     False  False      False  \n","2     False  False      False  \n","3     False  False      False  \n","4     False  False      False  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["mask.head()  # rows"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"EUjDyZSAMXQa"},"outputs":[],"source":["#Let's improve the process by using the function any that iterate through each row and return true for any x in the raw = true\n","mask = df.isnull().any(axis=1)"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"eNM2h2CINPVi"},"outputs":[{"data":{"text/plain":["0    False\n","1    False\n","2    False\n","3    False\n","4    False\n","dtype: bool"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["mask.head()"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"IEYkDWxxlRCU"},"outputs":[{"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'body'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn [44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[mask]\u001b[39m.\u001b[39;49mbody\u001b[39m.\u001b[39mhead() \u001b[39m# check body column\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   6293\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   6294\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   6295\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   6296\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   6297\u001b[0m ):\n\u001b[1;32m   6298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 6299\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'body'"]}],"source":["df[mask].body.head() # check body column"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"gEiWYigtlRCU","scrolled":true},"outputs":[{"data":{"text/plain":["Series([], Name: age, dtype: float64)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["df[mask].age.head() # check age column\n"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"vzHaL0oylRCV"},"outputs":[{"data":{"text/plain":["Series([], Name: embarked, dtype: int64)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df[mask].embarked.head() # check embarked column"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"FsA0_btzlRCV"},"outputs":[{"data":{"text/plain":["sex\n","1    843\n","0    466\n","Name: count, dtype: int64"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["#Use the .value_counts method to examine the counts of the values:\n","df.sex.value_counts(dropna=False) # How many male and female\n","# Assign dropna to false if you don't want to delete the missing values"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"EvizlUrVlRCW"},"outputs":[{"data":{"text/plain":["embarked\n","2    914\n","0    270\n","1    123\n","3      2\n","Name: count, dtype: int64"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["#Use the .value_counts method to examine the counts of the values:\n","df.embarked.value_counts(dropna=False)"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"rC3GHQOsPGwZ"},"outputs":[{"data":{"text/plain":["age\n","28.00    295\n","24.00     47\n","22.00     43\n","21.00     41\n","30.00     40\n","        ... \n","0.33       1\n","22.50      1\n","70.50      1\n","0.67       1\n","26.50      1\n","Name: count, Length: 98, dtype: int64"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["#Use the .value_counts method to examine the counts of the values:\n","df.age.value_counts(dropna=False)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"90WHHQjelRCW"},"outputs":[{"ename":"KeyError","evalue":"\"['body', 'cabin'] not found in axis\"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn [51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Delete raws with high percentage of missing values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m      3\u001b[0m      columns\u001b[39m=\u001b[39;49m[\n\u001b[1;32m      4\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mticket\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mhome.dest\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mboat\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mcabin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m      ]\n\u001b[1;32m     11\u001b[0m  )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5582\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5583\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5584\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5585\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5586\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5587\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5588\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5589\u001b[0m     )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4790\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n","\u001b[0;31mKeyError\u001b[0m: \"['body', 'cabin'] not found in axis\""]}],"source":["#Delete raws with high percentage of missing values\n","df = df.drop(\n","     columns=[\n","         \"name\",\n","         \"ticket\",\n","         \"home.dest\",\n","         \"boat\",\n","         \"body\",\n","         \"cabin\",\n","     ]\n"," )"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"8YBhVmJJlRCX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>survived</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>embarked</th>\n","      <th>boat</th>\n","      <th>home.dest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","      <td>1309.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2.294882</td>\n","      <td>0.381971</td>\n","      <td>0.644003</td>\n","      <td>29.503186</td>\n","      <td>0.498854</td>\n","      <td>0.385027</td>\n","      <td>33.281086</td>\n","      <td>1.495034</td>\n","      <td>21.576776</td>\n","      <td>270.578304</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.837836</td>\n","      <td>0.486055</td>\n","      <td>0.478997</td>\n","      <td>12.905241</td>\n","      <td>1.041658</td>\n","      <td>0.865560</td>\n","      <td>51.741500</td>\n","      <td>0.816130</td>\n","      <td>8.485711</td>\n","      <td>115.430272</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.170000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.895800</td>\n","      <td>1.000000</td>\n","      <td>17.000000</td>\n","      <td>195.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>323.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.275000</td>\n","      <td>2.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>3.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>512.329200</td>\n","      <td>3.000000</td>\n","      <td>27.000000</td>\n","      <td>369.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            pclass     survived          sex          age        sibsp  \\\n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000   \n","mean      2.294882     0.381971     0.644003    29.503186     0.498854   \n","std       0.837836     0.486055     0.478997    12.905241     1.041658   \n","min       1.000000     0.000000     0.000000     0.170000     0.000000   \n","25%       2.000000     0.000000     0.000000    22.000000     0.000000   \n","50%       3.000000     0.000000     1.000000    28.000000     0.000000   \n","75%       3.000000     1.000000     1.000000    35.000000     1.000000   \n","max       3.000000     1.000000     1.000000    80.000000     8.000000   \n","\n","             parch         fare     embarked         boat    home.dest  \n","count  1309.000000  1309.000000  1309.000000  1309.000000  1309.000000  \n","mean      0.385027    33.281086     1.495034    21.576776   270.578304  \n","std       0.865560    51.741500     0.816130     8.485711   115.430272  \n","min       0.000000     0.000000     0.000000     0.000000     0.000000  \n","25%       0.000000     7.895800     1.000000    17.000000   195.000000  \n","50%       0.000000    14.454200     2.000000    27.000000   323.000000  \n","75%       0.000000    31.275000     2.000000    27.000000   369.000000  \n","max       9.000000   512.329200     3.000000    27.000000   369.000000  "]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["#Use the attribute describe to check whether you managed to delete the columns\n","#Compare it with the above df.describe()\n","df.describe()"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"gXYVw4FSlRCX"},"outputs":[],"source":["#Working with missing data\n","\n","#Populate age missing values with thier median\n","\n","df['age'] = df['age'].fillna(df['age'].median())\n","\n","#Populate embarked missing values with high occurrence value\n","\n","df['embarked'] = df['embarked'].fillna('S')\n","\n","# map sex to a numeric type\n","df.sex = df.sex.map({'male': 1, 'female': 0})\n","\n","# map embarked to a numeric type\n","df.embarked = df.embarked.map({'S': 2, 'C': 1, 'Q':0})\n","\n","#fill any other missing value with 0 (is not good practice but to avoid common error of NaN value still exist)\n","df.fillna(0,inplace=True)"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"2qAcgv-IlRCY"},"outputs":[{"name":"stdout","output_type":"stream","text":["0       0.0\n","1       0.0\n","2       0.0\n","3       0.0\n","4       0.0\n","       ... \n","1304    0.0\n","1305    0.0\n","1306    0.0\n","1307    0.0\n","1308    0.0\n","Name: sex, Length: 1309, dtype: float64\n"]}],"source":["print(df.sex)"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"IZmMckCslRCY"},"outputs":[],"source":["#Splitting data into training and testing datasets\n","from sklearn.model_selection import train_test_split\n","#Assign survived column (targets) to y\n","y = df.survived\n","#Delete survived column from X (samples)\n","X = df.drop(columns=\"survived\")\n","#Now split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"Wc_SICKilRCY"},"outputs":[{"name":"stdout","output_type":"stream","text":["1182    1\n","1106    0\n","558     1\n","1125    0\n","793     0\n","       ..\n","583     1\n","332     0\n","1293    0\n","1115    0\n","1104    0\n","Name: survived, Length: 916, dtype: int64\n"]}],"source":["#check the y_train (target)\n","print(y_train)"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"RXo5Cr6SlRCY","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["      pclass                                               name  sex   age  \\\n","1182       3                   Salkjelsvik, Miss. Anna Kristine  0.0  21.0   \n","1106       3             Panula, Mrs. Juha (Maria Emilia Ojala)  0.0  41.0   \n","558        2                      Silven, Miss. Lyyli Karoliina  0.0  18.0   \n","1125       3                               Petersen, Mr. Marius  0.0  24.0   \n","793        3                         Elsbury, Mr. William James  0.0  47.0   \n","...      ...                                                ...  ...   ...   \n","583        2  Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Mi...  0.0  40.0   \n","332        2                     Baimbrigge, Mr. Charles Robert  0.0  23.0   \n","1293       3                  Williams, Mr. Howard Hugh \"Harry\"  0.0  28.0   \n","1115       3                                 Pedersen, Mr. Olaf  0.0  28.0   \n","1104       3                          Panula, Mr. Ernesti Arvid  0.0  16.0   \n","\n","      sibsp  parch      ticket     fare  embarked  boat  home.dest  \n","1182      0      0      343120   7.6500       0.0    24        369  \n","1106      0      5     3101295  39.6875       0.0    27        369  \n","558       0      2      250652  13.0000       0.0    10        118  \n","1125      0      0      342441   8.0500       0.0    27        369  \n","793       0      0    A/5 3902   7.2500       0.0    27        165  \n","...     ...    ...         ...      ...       ...   ...        ...  \n","583       0      0  C.A. 33595  15.7500       0.0    21          1  \n","332       0      0  C.A. 31030  10.5000       0.0    27        138  \n","1293      0      0    A/5 2466   8.0500       0.0    27        369  \n","1115      0      0      345498   7.7750       0.0    27        369  \n","1104      4      1     3101295  39.6875       0.0    27        369  \n","\n","[916 rows x 11 columns]\n"]}],"source":["#check the X_train (samples)\n","print(X_train)"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"OxMGDMOmlRCZ"},"outputs":[{"ename":"ValueError","evalue":"could not convert string to float: 'Salkjelsvik, Miss. Anna Kristine'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn [58], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1509\u001b[0m     X,\n\u001b[1;32m   1510\u001b[0m     y,\n\u001b[1;32m   1511\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1512\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1513\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1514\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1515\u001b[0m )\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:2153\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\n\u001b[1;32m   2150\u001b[0m     \u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, copy: bool_t \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2151\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m   2152\u001b[0m     values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 2153\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   2154\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2155\u001b[0m         astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   2156\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   2157\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block\n\u001b[1;32m   2158\u001b[0m     ):\n\u001b[1;32m   2159\u001b[0m         \u001b[39m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[1;32m   2160\u001b[0m         \u001b[39mif\u001b[39;00m astype_is_view(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtypes\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m astype_is_view(\n\u001b[1;32m   2161\u001b[0m             values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   2162\u001b[0m         ):\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Salkjelsvik, Miss. Anna Kristine'"]}],"source":["#call the ML algorithm\n","from sklearn.linear_model import LogisticRegression\n","clf = LogisticRegression(solver='liblinear')\n","clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yz1tAaUlRCZ"},"outputs":[],"source":["#Get the predicted and expected\n","#Can you tell what is predicted and expected values represent?\n","#Can you derive the misclassified values (wrong)\n","predicted = clf.predict(X=X_test)\n","expected = y_test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7fkrCarlRCZ"},"outputs":[],"source":["#Now print the model accuracy\n","print(f'{clf.score(X_test, y_test):.2%}')\n","clf.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NiuASIbalRCZ"},"outputs":[],"source":["#Can you evaluate and validate the model using k-fold?\n","#Can you get the confusion matrix?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xXrnbusZlRCa"},"outputs":[],"source":["#Save and test the model\n","import pickle\n","\n","# Save the trained model as a pickle string.\n","saved_model = pickle.dumps(clf)\n","\n","# Load the pickled model\n","clf_from_pickle = pickle.loads(saved_model)\n","\n","# Use the loaded pickled model to make predictions\n","clf_from_pickle.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fb36HFEtlRCa"},"outputs":[],"source":["# To save a machine learning model produced by scikit-learn (sklearn), you can use Python's joblib library,\n","# which is often preferred for saving scikit-learn models due to its efficiency.\n","\n","#First, ensure you have the joblib library installed. If you don't have it, you can install it using pip:\n","\n","# pip install joblib\n","\n","# Once you have your scikit-learn model trained and ready to save, import joblib:\n","import joblib\n","\n","\n","# Save the model as a pickle in a file\n","# You can use the joblib.dump() function. Provide the model and the file path where you want to save it:\n","joblib.dump(clf, 'filename.pkl')\n","\n","# Load the model from the file\n","# Your scikit-learn model is now saved to the specified file with the \".pkl\" extension.\n","# To load the model at a later time for use, you can use joblib.load():\n","clf_from_joblib = joblib.load('filename.pkl')\n","\n","# Use the loaded model to make predictions\n","clf_from_joblib.predict(X_test)\n","\n","# This process allows you to save and load scikit-learn models efficiently, preserving their state for future use without the need to retrain them."]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
